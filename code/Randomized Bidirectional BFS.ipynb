{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywikibot\n",
    "import collections\n",
    "from util import *\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store things as pairs: (queue, dict) where queue is\n",
    "# the queue associated to a bfs, and dict is\n",
    "# a dictionary sending each neighbor of a previous element of queue\n",
    "# to its parent that showed up earliest in the list.\n",
    "# A possible future update is to also include the distance\n",
    "# from the origin in the dict, so the image of the dict\n",
    "# would be an ordered pair (parent, distance).\n",
    "# Another potential improvement is to expand the breadth-first search\n",
    "# on the side whose dictionary is smaller, rather than just alternating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates a pair and returns 1 if it finds a path,\n",
    "# 0 if it does not find a path but updates successfully,\n",
    "# and -1 if there is nowhere to expand.\n",
    "# By default, the first pair is the one updated.\n",
    "# careful_bookkeeping means that the pairs will be updated correctly\n",
    "# even if a path is found.\n",
    "def expand_one_node(pair1, pair2, expand_first = True, pair1_to_pair2 = True, careful_bookkeeping=True):\n",
    "    if not expand_first:\n",
    "        return expand_one_side(pair2, pair1, pair1_to_pair2 = not pair1_to_pair2, careful_bookkeeping = careful_bookkeeping)\n",
    "    \n",
    "    try:\n",
    "        item_to_expand, path = pair1[0].popleft()\n",
    "        #print(item_to_expand)\n",
    "\n",
    "        if pair1_to_pair2:\n",
    "            potential_expansions = item_to_expand.get_successors()\n",
    "        else:\n",
    "            potential_expansions = item_to_expand.get_predecessors()\n",
    "            \n",
    "        # good potential expansions are those that have not been seen before\n",
    "        # in either dictionary.  It is not completely obvious, but not hard to show\n",
    "        # that if we get stuck by avoiding words in this way, then there is no path\n",
    "        # from start to end.\n",
    "        good_potential_expansions = []\n",
    "        for item in potential_expansions:  \n",
    "            if valid_page(item.title()):\n",
    "                if not careful_bookkeeping:\n",
    "                    if item in pair2[1].keys():\n",
    "                        # if we have seen this item before when expanding the other pair\n",
    "                        pair1[0].append((item, path + [item]))\n",
    "                        return 1\n",
    "                    elif item not in pair1[1].keys():\n",
    "                        good_potential_expansions.append((item, path + [item]))\n",
    "                        pair1[1][item] = item_to_expand\n",
    "                else:\n",
    "                    pass #TODO\n",
    "        \n",
    "        pair1[0].extend(good_potential_expansions)\n",
    "        \n",
    "    except:\n",
    "        # If the queue is empty.\n",
    "        #\n",
    "        # In the case of BFS, this case should never occur\n",
    "        # because empty queues are caught in expand_one_side()\n",
    "        # and moreover, if the queue is empty, the condition in\n",
    "        # the for loop in expand_one_side() is never true, so\n",
    "        # this method never gets called anyway.\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expands every node in one pair\n",
    "# Which pair depends on the value of expand_first\n",
    "# which direction to expand (linksfrom or backlinks) depends on pair1_to_pair2\n",
    "#\n",
    "# Returns an ordered pair (result, num_expansions)\n",
    "# where result indicates whether a path was found\n",
    "# and num_expansions indicates how many nodes were expanded\n",
    "def expand_one_side(pair1, pair2, expand_first = True, pair1_to_pair2 = True, careful_bookkeeping=True):    \n",
    "    if expand_first:\n",
    "        num_to_expand = len(pair1[0])\n",
    "    else:\n",
    "        num_to_expand = len(pair2[0])\n",
    "    \n",
    "    # This if condition could be moved to below the for loop\n",
    "    # and it might be marginally faster, but I think\n",
    "    # it's better style to put it here\n",
    "    if num_to_expand == 0:\n",
    "        return (-1,0)\n",
    "    \n",
    "    for i in range(num_to_expand):\n",
    "        result = expand_one_node(pair1, pair2, expand_first, pair1_to_pair2, careful_bookkeeping)\n",
    "        if result != None:\n",
    "            return (result,i+1)\n",
    "        \n",
    "    return (0,num_to_expand)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_first means that the path works by\n",
    "# travelling down the queue of pair1\n",
    "# followed by going backwards down pair2;\n",
    "# not use_first means the opposite.\n",
    "def generate_path(pair1,pair2,use_first):\n",
    "    if use_first:\n",
    "        endpoint, path = pair1[0].pop()\n",
    "        dict = pair2[1]\n",
    "        while endpoint != None:\n",
    "            endpoint = dict[endpoint]\n",
    "            path.append(endpoint)\n",
    "        path = path[:-1]\n",
    "    else:\n",
    "        # This is equivalent to the following:\n",
    "        # path = generate_path(pair2,pair1,not use_first)\n",
    "        # path.reverse()\n",
    "        endpoint, path = pair2[0].pop()\n",
    "        dict = pair1[1]\n",
    "        while endpoint != None:\n",
    "            endpoint = dict[endpoint]\n",
    "            path.append(endpoint)\n",
    "        path = path[:-1]\n",
    "        path.reverse()\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_use_first(previous_use_first, pair1, pair2):\n",
    "    return not previous_use_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if return_expansions == False, the output is the path as a list\n",
    "# if return_expansions == True, the output is a tuple (path, num_expansions)\n",
    "# where num_epansions is the number of nodes expanded.\n",
    "# In either case, the number of nodes expanded is counted;\n",
    "# return_expansions only affects whether it is returned\n",
    "def bidirectional_BFS_graph(start, end, return_expansions=False):\n",
    "    queue1 = collections.deque()\n",
    "    queue2 = collections.deque()\n",
    "    num_expansions = 0\n",
    "    \n",
    "    queue1.append((start,[start]))\n",
    "    queue2.append((end,[end]))\n",
    "    dict1 = {start:None}\n",
    "    dict2 = {end:None}\n",
    "\n",
    "    use_first = True\n",
    "    while True:\n",
    "        result = expand_one_side((queue1, dict1), (queue2, dict2), expand_first = use_first, careful_bookkeeping = False)\n",
    "        num_expansions += result[1]\n",
    "        if result[0] == 1:\n",
    "            path = generate_path((queue1,dict1),(queue2,dict2),use_first)\n",
    "            if return_expansions:\n",
    "                return (path,num_expansions)\n",
    "            else:\n",
    "                return path\n",
    "        elif result[0] == -1:\n",
    "            if return_expansions:\n",
    "                return (False, num_expansions)\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "        use_first = set_use_first(use_first, (queue1, dict1), (queue2, dict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageNode:\n",
    "    def __init__(self,page):\n",
    "        self.page = page\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.page)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self.page)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        try:\n",
    "            return self.page == other.page\n",
    "        except:\n",
    "            # If other does not have a page attribute\n",
    "            # (Main intended use case: If other == None)\n",
    "            return False\n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return not self == other\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.page)\n",
    "    \n",
    "    def title(self):\n",
    "        return self.page.title()\n",
    "        \n",
    "    def get_successors(self):\n",
    "        pages = [PageNode(page) for page in list(self.page.linkedPages())]\n",
    "        random.shuffle(pages)\n",
    "        return pages\n",
    "    \n",
    "    def get_predecessors(self):\n",
    "        pages = [PageNode(page) for page in list(self.page.backlinks())]\n",
    "        random.shuffle(pages)\n",
    "        return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = pywikibot.Site(\"en\", \"wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PageNode_from_title(title):\n",
    "    return PageNode(pywikibot.Page(site,title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_BFS(start, end):\n",
    "    return bidirectional_BFS_graph(PageNode_from_title(start),PageNode_from_title(end), return_expansions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = get_samples(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_search(search_method, search_tuples, **kwargs):\n",
    "    results = {}\n",
    "    for start, goal in tqdm(search_tuples):\n",
    "        results[(start, goal)] = search_method(start, goal, **kwargs)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [28:55<00:00, 11.51s/it]\n"
     ]
    }
   ],
   "source": [
    "output = run_search(bidirectional_BFS, examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Transhumanism',\n",
       "  'Saturn'): ([Page('Transhumanism'),\n",
       "   Page('Volcanic winter'),\n",
       "   Page('Sun'),\n",
       "   Page('Saturn')], 6),\n",
       " ('Vacuum',\n",
       "  'Jim Henson'): ([Page('Vacuum'),\n",
       "   Page('Incandescent light bulb'),\n",
       "   Page('Easy-Bake Oven'),\n",
       "   Page('Jim Henson')], 105),\n",
       " ('Earth',\n",
       "  'Chimpanzee'): ([Page('Earth'),\n",
       "   Page('History of the world'),\n",
       "   Page('Technology'),\n",
       "   Page('Chimpanzee')], 5),\n",
       " ('Renaissance',\n",
       "  'Dancing with the Stars'): ([Page('Renaissance'),\n",
       "   Page('Italians'),\n",
       "   Page('Gianni Rivera'),\n",
       "   Page('Dancing with the Stars')], 17),\n",
       " ('dna',\n",
       "  'War of 1812'): ([Page('Dna'),\n",
       "   Page('DNA'),\n",
       "   Page('Agriculture'),\n",
       "   Page('Industrial Revolution'),\n",
       "   Page('War of 1812')], 8),\n",
       " ('Kidney',\n",
       "  'Wesley Snipes'): ([Page('Kidney'),\n",
       "   Page('Latin'),\n",
       "   Page('Proto-Indo-European language'),\n",
       "   Page('Michael Fassbender'),\n",
       "   Page('Wesley Snipes')], 449),\n",
       " ('Brown Bear',\n",
       "  'World Series'): ([Page('Brown Bear'),\n",
       "   Page('Brown bear'),\n",
       "   Page('Galápagos sea lion'),\n",
       "   Page('Colombia'),\n",
       "   Page('World Series')], 16),\n",
       " ('Copyright infringement',\n",
       "  'Bipolar junction transistor'): ([Page('Copyright infringement'),\n",
       "   Page('Patent troll'),\n",
       "   Page('Intel'),\n",
       "   Page('Bipolar junction transistor')], 4),\n",
       " ('Saxophone',\n",
       "  'Lactose intolerance'): ([Page('Saxophone'),\n",
       "   Page('Arundo donax'),\n",
       "   Page('Goat'),\n",
       "   Page('Lactose intolerance')], 55),\n",
       " ('World Health Organization',\n",
       "  'Life expectancy'): ([Page('World Health Organization'),\n",
       "   Page('South Korea'),\n",
       "   Page('Life expectancy')], 6),\n",
       " ('Sherlock Holmes',\n",
       "  'Knife'): ([Page('Sherlock Holmes'),\n",
       "   Page('Deduce, You Say!'),\n",
       "   Page('Daffy Duck and the Dinosaur'),\n",
       "   Page('Knife')], 3),\n",
       " ('River',\n",
       "  'Blood pressure'): ([Page('River'),\n",
       "   Page('Azerbaijan'),\n",
       "   Page('Black tea'),\n",
       "   Page('Blood pressure')], 9),\n",
       " ('Gin',\n",
       "  'Mountain'): ([Page('Gin'),\n",
       "   Page('Rakı'),\n",
       "   Page('Albania'),\n",
       "   Page('Mountain')], 14),\n",
       " ('Francis Ford Coppola',\n",
       "  'RNA'): ([Page('Francis Ford Coppola'),\n",
       "   Page('Luis Buñuel'),\n",
       "   Page('Severo Ochoa'),\n",
       "   Page('RNA')], 32),\n",
       " ('Association football',\n",
       "  'lacrosse'): ([Page('Association football'), Page('Lacrosse')], 1),\n",
       " ('Muscle car',\n",
       "  'Nuclear Power'): ([Page('Muscle car'),\n",
       "   Page('Electric vehicle'),\n",
       "   Page('Nuclear Power')],\n",
       "  292),\n",
       " ('Statistics', 'angelina jolie'): (False, 601),\n",
       " ('Caroline Kennedy',\n",
       "  'Joan Baez'): ([Page('Caroline Kennedy'),\n",
       "   Page('Bouffant'),\n",
       "   Page('Joan Baez')], 104),\n",
       " ('Written language',\n",
       "  'speech'): ([Page('Written language'),\n",
       "   Page('English language'),\n",
       "   Page('Near-open front unrounded vowel'),\n",
       "   Page('Speech')], 4),\n",
       " ('Waterboarding',\n",
       "  'Ecology'): ([Page('Waterboarding'),\n",
       "   Page(\"St. Martin's Press\"),\n",
       "   Page('Nature India'),\n",
       "   Page('Ecology')], 3),\n",
       " ('Dance music',\n",
       "  'Pathology'): ([Page('Dance music'),\n",
       "   Page('Ibiza'),\n",
       "   Page('Biodiversity'),\n",
       "   Page('Pathology')], 26),\n",
       " ('Computer science',\n",
       "  'Death of Adolf Hitler'): ([Page('Computer science'),\n",
       "   Page('Photo manipulation'),\n",
       "   Page('Joseph Stalin'),\n",
       "   Page('Death of Adolf Hitler')], 16),\n",
       " ('Bavaria',\n",
       "  'Canadians'): ([Page('Bavaria'),\n",
       "   Page('KUKA'),\n",
       "   Page('Canada'),\n",
       "   Page('Canadians')], 6),\n",
       " ('Jellyfish',\n",
       "  'Bilirubin'): ([Page('Jellyfish'),\n",
       "   Page('Psilocybin mushroom'),\n",
       "   Page('Aromatic hydrocarbon'),\n",
       "   Page('Bilirubin')], 3),\n",
       " ('War of 1812',\n",
       "  'Southern Europe'): ([Page('War of 1812'),\n",
       "   Page('French invasion of Russia'),\n",
       "   Page('Orientalism'),\n",
       "   Page('Southern Europe')], 3),\n",
       " ('Al-Qaeda',\n",
       "  'Radio'): ([Page('Al-Qaeda'),\n",
       "   Page('Ethiopia'),\n",
       "   Page('Culture of Ethiopia'),\n",
       "   Page('Radio')], 6),\n",
       " ('Cologne',\n",
       "  'Battleship'): ([Page('Cologne'),\n",
       "   Page('Bergen'),\n",
       "   Page('Coastal artillery'),\n",
       "   Page('Battleship')], 5),\n",
       " ('Megalodon',\n",
       "  'Coaxial cable'): ([Page('Megalodon'),\n",
       "   Page('Antigua and Barbuda'),\n",
       "   Page('Telecommunications in Antigua and Barbuda'),\n",
       "   Page('Coaxial cable')], 4),\n",
       " ('Ralph Waldo Emerson',\n",
       "  'Marine biology'): ([Page('Ralph Waldo Emerson'),\n",
       "   Page('Arthur Schopenhauer'),\n",
       "   Page('Joseph Campbell'),\n",
       "   Page('Marine biology')], 11),\n",
       " ('Documentary film',\n",
       "  'Bacteria'): ([Page('Documentary film'),\n",
       "   Page('Crush fetish'),\n",
       "   Page('Coprophagia'),\n",
       "   Page('Bacteria')], 3),\n",
       " ('Auto racing',\n",
       "  'Ethernet'): ([Page('Auto racing'),\n",
       "   Page('Olympic Games'),\n",
       "   Page('European Broadcasting Union'),\n",
       "   Page('Ethernet')], 11),\n",
       " ('Michelangelo',\n",
       "  'Horror Fiction'): ([Page('Michelangelo'),\n",
       "   Page('Raphael Cartoons'),\n",
       "   Page('Francisco Goya'),\n",
       "   Page('Gothic fiction'),\n",
       "   Page('Algernon Blackwood'),\n",
       "   Page('Horror Fiction')], 607),\n",
       " ('Pony Express',\n",
       "  'Jacob'): ([Page('Pony Express'),\n",
       "   Page('Oxford University Press'),\n",
       "   Page('Church Fathers'),\n",
       "   Page('Jacob')], 5),\n",
       " ('Prussia',\n",
       "  'nitrogen'): ([Page('Prussia'),\n",
       "   Page('Prussian Homage (painting)'),\n",
       "   Page('Jagiellonian University'),\n",
       "   Page('Nitrogen')], 5),\n",
       " ('Americans',\n",
       "  'Rhodesia'): ([Page('Americans'),\n",
       "   Page('English language'),\n",
       "   Page('The Bahamas'),\n",
       "   Page('Rhodesia')], 6),\n",
       " ('Nobel Prize in Physiology or Medicine',\n",
       "  'World Trade Organization'): ([Page('Nobel Prize in Physiology or Medicine'),\n",
       "   Page('Imperial College Press'),\n",
       "   Page('Economics'),\n",
       "   Page('World Trade Organization')], 5),\n",
       " ('Engine',\n",
       "  'Multi-sport event'): ([Page('Engine'),\n",
       "   Page('Fire engine'),\n",
       "   Page('World Police and Fire Games'),\n",
       "   Page('Multi-sport event')], 23),\n",
       " ('Church of England',\n",
       "  'African-American music'): ([Page('Church of England'),\n",
       "   Page('Anglican churches in the Americas'),\n",
       "   Page('United States'),\n",
       "   Page('African-American music')], 19),\n",
       " ('Sheep',\n",
       "  'James II of England'): ([Page('Sheep'),\n",
       "   Page('The New York Times'),\n",
       "   Page('New York metropolitan area'),\n",
       "   Page('James II of England')], 8),\n",
       " ('William Shakespeare',\n",
       "  'Nevada'): ([Page('William Shakespeare'),\n",
       "   Page('The Story of Edgar Sawtelle'),\n",
       "   Page('Wisconsin'),\n",
       "   Page('Nevada')], 9),\n",
       " ('Ornithology',\n",
       "  'Google Chrome'): ([Page('Ornithology'),\n",
       "   Page('International Standard Serial Number'),\n",
       "   Page('JPEG 2000'),\n",
       "   Page('Google Chrome')], 17),\n",
       " ('Radiohead',\n",
       "  'Armageddon'): ([Page('Radiohead'),\n",
       "   Page('Pitchfork (website)'),\n",
       "   Page('Reddit'),\n",
       "   Page('Armageddon')], 31),\n",
       " ('Ghetto',\n",
       "  'Dream'): ([Page('Ghetto'),\n",
       "   Page('Jewish diaspora'),\n",
       "   Page('Jewish culture'),\n",
       "   Page('Dream')], 6),\n",
       " ('Adolf Hitler',\n",
       "  'Vermont'): ([Page('Adolf Hitler'),\n",
       "   Page('Sherron Watkins'),\n",
       "   Page('United States'),\n",
       "   Page('Vermont')], 9),\n",
       " ('Parthenon',\n",
       "  'Mathematics'): ([Page('Parthenon'),\n",
       "   Page('Iberian Peninsula'),\n",
       "   Page('Valencian Community'),\n",
       "   Page('Mathematics')], 3),\n",
       " ('Potato',\n",
       "  \"Alzheimer's disease\"): ([Page('Potato'),\n",
       "   Page('Copper in health'),\n",
       "   Page(\"Alzheimer's disease\")], 137),\n",
       " ('Comedian',\n",
       "  'Mark Wahlberg'): ([Page('Comedian'),\n",
       "   Page('Stephen Colbert'),\n",
       "   Page('Steve Carell'),\n",
       "   Page('Mark Wahlberg')], 4),\n",
       " ('Bruce Lee',\n",
       "  'Jules Verne'): ([Page('Bruce Lee'),\n",
       "   Page('Shannon Lee'),\n",
       "   Page('Jackie Chan'),\n",
       "   Page('Jules Verne')], 4),\n",
       " ('Dictionary',\n",
       "  'Graphical User Interface'): ([Page('Dictionary'),\n",
       "   Page('Lexical Markup Framework'),\n",
       "   Page('Universal Coded Character Set'),\n",
       "   Page('Graphical User Interface')], 17),\n",
       " ('Moors',\n",
       "  'Personal computer'): ([Page('Moors'),\n",
       "   Page('International Standard Book Number'),\n",
       "   Page('Open Document Architecture'),\n",
       "   Page('Personal computer')], 6),\n",
       " ('Humid subtropical climate',\n",
       "  'Mammal'): ([Page('Humid subtropical climate'),\n",
       "   Page('Central Africa'),\n",
       "   Page('Bushveld'),\n",
       "   Page('Mammal')], 3),\n",
       " ('Yellowstone National Park',\n",
       "  'Credit card'): ([Page('Yellowstone National Park'),\n",
       "   Page('Pony Express'),\n",
       "   Page('History of Wells Fargo'),\n",
       "   Page('Credit card')], 6),\n",
       " ('Jim Carrey',\n",
       "  'Latitude'): ([Page('Jim Carrey'),\n",
       "   Page('National Rifle Association'),\n",
       "   Page('Geographic coordinate system'),\n",
       "   Page('Latitude')], 4),\n",
       " ('Natural Environment',\n",
       "  'Sociology'): ([Page('Natural Environment'),\n",
       "   Page('Natural environment'),\n",
       "   Page('Geography'),\n",
       "   Page('Sociology')], 3),\n",
       " ('Profession',\n",
       "  'List of U.S. states and territories by area'): ([Page('Profession'),\n",
       "   Page('United Kingdom'),\n",
       "   Page('Alaska'),\n",
       "   Page('List of U.S. states and territories by area')], 22),\n",
       " ('Nevada',\n",
       "  'Web search engine'): ([Page('Nevada'),\n",
       "   Page('Alexander von Humboldt'),\n",
       "   Page('International Standard Serial Number'),\n",
       "   Page('Web search engine')], 3),\n",
       " ('World War II',\n",
       "  'Mathematics'): ([Page('World War II'),\n",
       "   Page('Rhine-Ruhr'),\n",
       "   Page('Würzburg'),\n",
       "   Page('Mathematics')], 3),\n",
       " ('Brain tumor',\n",
       "  'Pistol'): ([Page('Brain tumor'),\n",
       "   Page('Fluorescence'),\n",
       "   Page('Flare'),\n",
       "   Page('Pistol')], 4),\n",
       " ('The Cosby Show',\n",
       "  'Eurozone'): ([Page('The Cosby Show'),\n",
       "   Page('Sitcom'),\n",
       "   Page('Spain'),\n",
       "   Page('Eurozone')], 12),\n",
       " ('Lead',\n",
       "  'Typhoid fever'): ([Page('Lead'),\n",
       "   Page('Thomas Midgley Jr.'),\n",
       "   Page('Columbus, Ohio'),\n",
       "   Page('Typhoid fever')], 28),\n",
       " ('Fashion',\n",
       "  'Bette Midler'): ([Page('Fashion'),\n",
       "   Page(\"Men's skirts\"),\n",
       "   Page('The Tonight Show Starring Johnny Carson'),\n",
       "   Page('Bette Midler')], 3),\n",
       " ('Death',\n",
       "  'Apple Lisa'): ([Page('Death'),\n",
       "   Page('Brazil'),\n",
       "   Page('Acronym'),\n",
       "   Page('Apple Lisa')], 38),\n",
       " ('Electron',\n",
       "  'Bosnia and Herzegovina'): ([Page('Electron'),\n",
       "   Page('History of electromagnetic theory'),\n",
       "   Page('Iraq'),\n",
       "   Page('Bosnia and Herzegovina')], 5),\n",
       " ('String theory',\n",
       "  'Gastroesophageal reflux disease'): ([Page('String theory'),\n",
       "   Page('Albert Einstein'),\n",
       "   Page('Rudolph Nissen'),\n",
       "   Page('Gastroesophageal reflux disease')], 24),\n",
       " ('Nuclear Power',\n",
       "  'Breakfast'): ([Page('Nuclear Power'),\n",
       "   Page('Nuclear power'),\n",
       "   Page('Food'),\n",
       "   Page('Breakfast')], 3),\n",
       " ('Aryan',\n",
       "  'Magnetic resonance imaging'): ([Page('Aryan'),\n",
       "   Page('Jainism'),\n",
       "   Page('Animal rights'),\n",
       "   Page('Magnetic resonance imaging')], 5),\n",
       " ('Persecution of Christians',\n",
       "  'Wall Street'): ([Page('Persecution of Christians'),\n",
       "   Page('Slavery'),\n",
       "   Page('Household income in the United States'),\n",
       "   Page('Wall Street')], 9),\n",
       " ('Tomato',\n",
       "  'Stock market'): ([Page('Tomato'),\n",
       "   Page('Caribbean'),\n",
       "   Page('Silicon Valley'),\n",
       "   Page('Stock market')], 5),\n",
       " ('Nuclear warfare',\n",
       "  'DNA replication'): ([Page('Nuclear warfare'),\n",
       "   Page('Integral fast reactor'),\n",
       "   Page('Chain reaction'),\n",
       "   Page('DNA replication')], 3),\n",
       " ('Dimension',\n",
       "  'Memory'): ([Page('Dimension'),\n",
       "   Page('Superstring theory'),\n",
       "   Page('Theory of everything'),\n",
       "   Page('Memory')], 7),\n",
       " ('Periodic table',\n",
       "  'Gastroesophageal reflux disease'): ([Page('Periodic table'),\n",
       "   Page('Cobalt'),\n",
       "   Page('Implant (medicine)'),\n",
       "   Page('Gastroesophageal reflux disease')], 10),\n",
       " ('Southern California',\n",
       "  'Diazepam'): ([Page('Southern California'),\n",
       "   Page('United States'),\n",
       "   Page('Eminem'),\n",
       "   Page('Diazepam')], 11),\n",
       " ('Charles Bronson',\n",
       "  'Architecture'): ([Page('Charles Bronson'),\n",
       "   Page('Death Wish 3'),\n",
       "   Page('London'),\n",
       "   Page('Architecture')], 4),\n",
       " ('Romanticism',\n",
       "  'Sigmund Freud'): ([Page('Romanticism'),\n",
       "   Page('Psychology'),\n",
       "   Page('Sigmund Freud')], 37),\n",
       " ('Internal combustion engine',\n",
       "  'Ballet'): ([Page('Internal combustion engine'),\n",
       "   Page('Taxicab'),\n",
       "   Page('Havana'),\n",
       "   Page('Ballet')], 17),\n",
       " ('J. R. R. Tolkien',\n",
       "  'Luciano Pavarotti'): ([Page('J. R. R. Tolkien'),\n",
       "   Page('Cryptanalysis'),\n",
       "   Page('Italy'),\n",
       "   Page('Luciano Pavarotti')], 53),\n",
       " ('Ecosystem',\n",
       "  'Four Tops'): ([Page('Ecosystem'),\n",
       "   Page('Washington (state)'),\n",
       "   Page('Soul music'),\n",
       "   Page('Four Tops')], 23),\n",
       " ('Frank Gehry',\n",
       "  'Will Smith'): ([Page('Frank Gehry'),\n",
       "   Page('Walter Annenberg'),\n",
       "   Page(\"New Year's Eve\"),\n",
       "   Page('Will Smith')], 13),\n",
       " ('Feces',\n",
       "  'Entertainment'): ([Page('Feces'),\n",
       "   Page('Archaeology'),\n",
       "   Page('History of literature'),\n",
       "   Page('Entertainment')], 5),\n",
       " ('Louis Armstrong',\n",
       "  'Airline'): ([Page('Louis Armstrong'),\n",
       "   Page('Riverboat'),\n",
       "   Page('Hydrofoil'),\n",
       "   Page('Airline')], 32),\n",
       " ('Constantinople',\n",
       "  'Montreal'): ([Page('Constantinople'),\n",
       "   Page('Balkans'),\n",
       "   Page('London'),\n",
       "   Page('Montreal')], 14),\n",
       " ('Pulmonary embolism',\n",
       "  'Periodic table'): ([Page('Pulmonary embolism'),\n",
       "   Page('Ultrasound'),\n",
       "   Page('Chemically inert'),\n",
       "   Page('Periodic table')], 7),\n",
       " ('Onomatopoeia',\n",
       "  'Apple Lisa'): ([Page('Onomatopoeia'),\n",
       "   Page('Oxford English Dictionary'),\n",
       "   Page('Microsoft Windows'),\n",
       "   Page('Apple Lisa')], 22),\n",
       " ('Birdman (rapper)',\n",
       "  'Taxonomy (biology)'): ([Page('Birdman (rapper)'),\n",
       "   Page('Drug possession'),\n",
       "   Page('Anadenanthera colubrina'),\n",
       "   Page('Taxonomy (biology)')], 5),\n",
       " ('Lacrosse',\n",
       "  'Satire'): ([Page('Lacrosse'),\n",
       "   Page('New York University'),\n",
       "   Page('Martin Scorsese'),\n",
       "   Page('Satire')], 18),\n",
       " ('Chemical reaction',\n",
       "  'Matter'): ([Page('Chemical reaction'),\n",
       "   Page('Lead'),\n",
       "   Page('Chemical element'),\n",
       "   Page('Matter')], 7),\n",
       " ('Continental Army',\n",
       "  'Organization'): ([Page('Continental Army'),\n",
       "   Page('President of the United States'),\n",
       "   Page('Public relations'),\n",
       "   Page('Organization')], 8),\n",
       " ('Americans',\n",
       "  'West Indies'): ([Page('Americans'),\n",
       "   Page('Norwegian Americans'),\n",
       "   Page('Pacific Northwest'),\n",
       "   Page('West Indies')], 3),\n",
       " ('Carrie Fisher',\n",
       "  'Ant'): ([Page('Carrie Fisher'),\n",
       "   Page('Autopsy'),\n",
       "   Page('Fossil'),\n",
       "   Page('Ant')], 28),\n",
       " ('Climate',\n",
       "  'Atmosphere of Earth'): ([Page('Climate'), Page('Atmosphere of Earth')], 1),\n",
       " ('Train',\n",
       "  'Envy'): ([Page('Train'),\n",
       "   Page('Diesel locomotive'),\n",
       "   Page('Human'),\n",
       "   Page('Envy')],\n",
       "  19),\n",
       " ('Early Middle Ages',\n",
       "  'Ku Klux Klan'): ([Page('Early Middle Ages'),\n",
       "   Page('Girona'),\n",
       "   Page('Nashville, Tennessee'),\n",
       "   Page('Ku Klux Klan')], 3),\n",
       " ('Augustus',\n",
       "  'Magnetic field'): ([Page('Augustus'),\n",
       "   Page('Digital object identifier'),\n",
       "   Page('ISO/IEC 15693'),\n",
       "   Page('Magnetic field')], 38),\n",
       " ('Parthenon',\n",
       "  'United Nations Charter'): ([Page('Parthenon'),\n",
       "   Page('Mosque'),\n",
       "   Page('Member states of the United Nations'),\n",
       "   Page('United Nations Charter')], 5),\n",
       " ('Metaphysics',\n",
       "  'Technology'): ([Page('Metaphysics'),\n",
       "   Page('Reality'),\n",
       "   Page('Measurement'),\n",
       "   Page('Technology')], 5),\n",
       " ('Polynesia',\n",
       "  'Queens of the Stone Age'): ([Page('Polynesia'),\n",
       "   Page('New England'),\n",
       "   Page('Sarah Silverman'),\n",
       "   Page('Queens of the Stone Age')], 47),\n",
       " ('Computer Multitasking', 'Broadway theatre'): (False, 2),\n",
       " ('Celsius',\n",
       "  'Wiki'): ([Page('Celsius'),\n",
       "   Page('National Institute of Standards and Technology'),\n",
       "   Page('United States Department of State'),\n",
       "   Page('Wiki')], 3),\n",
       " ('Mick Jagger',\n",
       "  'Personal digital assistant'): ([Page('Mick Jagger'),\n",
       "   Page('Smoke on the Water'),\n",
       "   Page('Video game'),\n",
       "   Page('Personal digital assistant')], 23),\n",
       " ('Ashley Massaro',\n",
       "  'Embedded system'): ([Page('Ashley Massaro'),\n",
       "   Page('Julia Landauer'),\n",
       "   Page('Stanford University'),\n",
       "   Page('Embedded system')], 4)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywikibot\n",
    "import collections\n",
    "from util import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store things as pairs: (queue, dict) where queue is\n",
    "# the queue associated to a bfs, and dict is\n",
    "# a dictionary sending each neighbor of a previous element of queue\n",
    "# to its parent that showed up earliest in the list.\n",
    "# A possible future update is to also include the distance\n",
    "# from the origin in the dict, so the image of the dict\n",
    "# would be an ordered pair (parent, distance).\n",
    "# Another potential improvement is to expand the breadth-first search\n",
    "# on the side whose dictionary is smaller, rather than just alternating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates a pair and returns 1 if it finds a path,\n",
    "# 0 if it does not find a path but updates successfully,\n",
    "# and -1 if there is nowhere to expand.\n",
    "# By default, the first pair is the one updated.\n",
    "# careful_bookkeeping means that the pairs will be updated correctly\n",
    "# even if a path is found.\n",
    "def expand_one_node(pair1, pair2, expand_first = True, pair1_to_pair2 = True, careful_bookkeeping=True):\n",
    "    if not expand_first:\n",
    "        return expand_one_node(pair2, pair1, pair1_to_pair2 = not pair1_to_pair2, careful_bookkeeping = careful_bookkeeping)\n",
    "    \n",
    "    try:\n",
    "        item_to_expand, path = pair1[0].popleft()\n",
    "        #print(item_to_expand)\n",
    "\n",
    "        if pair1_to_pair2:\n",
    "            potential_expansions = item_to_expand.get_successors()\n",
    "        else:\n",
    "            potential_expansions = item_to_expand.get_predecessors()\n",
    "            \n",
    "        # good potential expansions are those that have not been seen before\n",
    "        # in either dictionary.  It is not completely obvious, but not hard to show\n",
    "        # that if we get stuck by avoiding words in this way, then there is no path\n",
    "        # from start to end.\n",
    "        good_potential_expansions = []\n",
    "        for item in potential_expansions:  \n",
    "            if valid_page(item.title()):\n",
    "                if not careful_bookkeeping:\n",
    "                    if item in pair2[1].keys():\n",
    "                        # if we have seen this item before when expanding the other pair\n",
    "                        pair1[0].append((item, path + [item]))\n",
    "                        return 1\n",
    "                    elif item not in pair1[1].keys():\n",
    "                        good_potential_expansions.append((item, path + [item]))\n",
    "                        pair1[1][item] = item_to_expand\n",
    "                else:\n",
    "                    pass #TODO\n",
    "        \n",
    "        pair1[0].extend(good_potential_expansions)\n",
    "        \n",
    "    except:\n",
    "        # If the queue is empty.\n",
    "        #\n",
    "        # In the case of BFS, this case should never occur\n",
    "        # because empty queues are caught in expand_one_side()\n",
    "        # and moreover, if the queue is empty, the condition in\n",
    "        # the for loop in expand_one_side() is never true, so\n",
    "        # this method never gets called anyway.\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expands every node in one pair\n",
    "# Which pair depends on the value of expand_first\n",
    "# which direction to expand (linksfrom or backlinks) depends on pair1_to_pair2\n",
    "#\n",
    "# Returns an ordered pair (result, num_expansions)\n",
    "# where result indicates whether a path was found\n",
    "# and num_expansions indicates how many nodes were expanded\n",
    "def expand_one_side(pair1, pair2, expand_first = True, pair1_to_pair2 = True, careful_bookkeeping=True):    \n",
    "    if expand_first:\n",
    "        num_to_expand = len(pair1[0])\n",
    "    else:\n",
    "        num_to_expand = len(pair2[0])\n",
    "    \n",
    "    # This if condition could be moved to below the for loop\n",
    "    # and it might be marginally faster, but I think\n",
    "    # it's better style to put it here\n",
    "    if num_to_expand == 0:\n",
    "        return (-1,0)\n",
    "    \n",
    "    for i in range(num_to_expand):\n",
    "        result = expand_one_node(pair1, pair2, expand_first, pair1_to_pair2, careful_bookkeeping)\n",
    "        if result != None:\n",
    "            return (result,i+1)\n",
    "        \n",
    "    return (0,num_to_expand)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_first means that the path works by\n",
    "# travelling down the queue of pair1\n",
    "# followed by going backwards down pair2;\n",
    "# not use_first means the opposite.\n",
    "def generate_path(pair1,pair2,use_first):\n",
    "    if use_first:\n",
    "        endpoint, path = pair1[0].pop()\n",
    "        dict = pair2[1]\n",
    "        while endpoint != None:\n",
    "            endpoint = dict[endpoint]\n",
    "            path.append(endpoint)\n",
    "        path = path[:-1]\n",
    "    else:\n",
    "        # This is equivalent to the following:\n",
    "        # path = generate_path(pair2,pair1,not use_first)\n",
    "        # path.reverse()\n",
    "        endpoint, path = pair2[0].pop()\n",
    "        dict = pair1[1]\n",
    "        while endpoint != None:\n",
    "            endpoint = dict[endpoint]\n",
    "            path.append(endpoint)\n",
    "        path = path[:-1]\n",
    "        path.reverse()\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_use_first(previous_use_first, pair1, pair2):\n",
    "    return not previous_use_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if return_expansions == False, the output is the path as a list\n",
    "# if return_expansions == True, the output is a tuple (path, num_expansions)\n",
    "# where num_epansions is the number of nodes expanded.\n",
    "# In either case, the number of nodes expanded is counted;\n",
    "# return_expansions only affects whether it is returned\n",
    "def bidirectional_BFS_graph(start, end, return_expansions=False):\n",
    "    queue1 = collections.deque()\n",
    "    queue2 = collections.deque()\n",
    "    num_expansions = 0\n",
    "    \n",
    "    queue1.append((start,[start]))\n",
    "    queue2.append((end,[end]))\n",
    "    dict1 = {start:None}\n",
    "    dict2 = {end:None}\n",
    "\n",
    "    use_first = True\n",
    "    while True:\n",
    "        result = expand_one_side((queue1, dict1), (queue2, dict2), expand_first = use_first, careful_bookkeeping = False)\n",
    "        num_expansions += result[1]\n",
    "        if result[0] == 1:\n",
    "            path = generate_path((queue1,dict1),(queue2,dict2),use_first)\n",
    "            if return_expansions:\n",
    "                return (path,num_expansions)\n",
    "            else:\n",
    "                return path\n",
    "        elif result[0] == -1:\n",
    "            if return_expansions:\n",
    "                return (False, num_expansions)\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "        use_first = set_use_first(use_first, (queue1, dict1), (queue2, dict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageNode:\n",
    "    def __init__(self,page):\n",
    "        self.page = page\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.page)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self.page)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        try:\n",
    "            return self.page == other.page\n",
    "        except:\n",
    "            # If other does not have a page attribute\n",
    "            # (Main intended use case: If other == None)\n",
    "            return False\n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return not self == other\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.page)\n",
    "    \n",
    "    def title(self):\n",
    "        return self.page.title()\n",
    "        \n",
    "    def get_successors(self):\n",
    "        return [PageNode(page) for page in list(self.page.linkedPages())]\n",
    "    \n",
    "    def get_predecessors(self):\n",
    "        return [PageNode(page) for page in list(self.page.backlinks())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = pywikibot.Site(\"en\", \"wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PageNode_from_title(title):\n",
    "    return PageNode(pywikibot.Page(site,title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_BFS(start, end):\n",
    "    return bidirectional_BFS_graph(PageNode_from_title(start),PageNode_from_title(end), return_expansions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = get_samples(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_search(search_method, search_tuples, **kwargs):\n",
    "    results = {}\n",
    "    for start, goal in tqdm(search_tuples):\n",
    "        results[(start, goal)] = search_method(start, goal, **kwargs)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [28:50<00:00, 13.15s/it]\n"
     ]
    }
   ],
   "source": [
    "output = run_search(bidirectional_BFS, examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Transhumanism',\n",
       "  'Saturn'): ([Page('Transhumanism'),\n",
       "   Page('Space colonization'),\n",
       "   Page('Saturn')], 2),\n",
       " ('Vacuum',\n",
       "  'Jim Henson'): ([Page('Vacuum'),\n",
       "   Page('Incandescent light bulb'),\n",
       "   Page('Easy-Bake Oven'),\n",
       "   Page('Jim Henson')], 128),\n",
       " ('Earth',\n",
       "  'Chimpanzee'): ([Page('Earth'),\n",
       "   Page('Human evolution'),\n",
       "   Page('Chimpanzee')], 2),\n",
       " ('Renaissance',\n",
       "  'Dancing with the Stars'): ([Page('Renaissance'),\n",
       "   Page('Abstract expressionism'),\n",
       "   Page('Dance in the United States'),\n",
       "   Page('Dancing with the Stars')], 10),\n",
       " ('dna',\n",
       "  'War of 1812'): ([Page('Dna'),\n",
       "   Page('DNA'),\n",
       "   Page('Oxford University Press'),\n",
       "   Page('American Revolutionary War'),\n",
       "   Page('War of 1812')], 5),\n",
       " ('Kidney',\n",
       "  'Wesley Snipes'): ([Page('Kidney'),\n",
       "   Page('Conscience'),\n",
       "   Page('Humphrey Bogart'),\n",
       "   Page('Burt Lancaster'),\n",
       "   Page('Wesley Snipes')], 351),\n",
       " ('Brown Bear',\n",
       "  'World Series'): ([Page('Brown Bear'),\n",
       "   Page('Brown bear'),\n",
       "   Page('Tulare County, California'),\n",
       "   Page('Arizona Diamondbacks'),\n",
       "   Page('World Series')], 4),\n",
       " ('Copyright infringement',\n",
       "  'Bipolar junction transistor'): ([Page('Copyright infringement'),\n",
       "   Page('Anti-Counterfeiting Trade Agreement'),\n",
       "   Page('Intel'),\n",
       "   Page('Bipolar junction transistor')], 17),\n",
       " ('Saxophone',\n",
       "  'Lactose intolerance'): ([Page('Saxophone'),\n",
       "   Page('Arundo donax'),\n",
       "   Page('Goat'),\n",
       "   Page('Lactose intolerance')], 23),\n",
       " ('World Health Organization',\n",
       "  'Life expectancy'): ([Page('World Health Organization'),\n",
       "   Page('Death'),\n",
       "   Page('Life expectancy')], 2),\n",
       " ('Sherlock Holmes',\n",
       "  'Knife'): ([Page('Sherlock Holmes'),\n",
       "   Page('Anime'),\n",
       "   Page('Jōmon period'),\n",
       "   Page('Knife')], 36),\n",
       " ('River',\n",
       "  'Blood pressure'): ([Page('River'),\n",
       "   Page('Pressure'),\n",
       "   Page('Blood pressure')], 2),\n",
       " ('Gin',\n",
       "  'Mountain'): ([Page('Gin'),\n",
       "   Page('Aframomum melegueta'),\n",
       "   Page('Jimbu'),\n",
       "   Page('Mountain')], 6),\n",
       " ('Francis Ford Coppola',\n",
       "  'RNA'): ([Page('Francis Ford Coppola'),\n",
       "   Page('Alexandre Desplat'),\n",
       "   Page('University of California, Berkeley'),\n",
       "   Page('RNA')], 63),\n",
       " ('Association football',\n",
       "  'lacrosse'): ([Page('Association football'), Page('Lacrosse')], 1),\n",
       " ('Muscle car',\n",
       "  'Nuclear Power'): ([Page('Muscle car'),\n",
       "   Page('Electric vehicle'),\n",
       "   Page('Nuclear Power')],\n",
       "  2),\n",
       " ('Statistics', 'angelina jolie'): (False, 601),\n",
       " ('Caroline Kennedy',\n",
       "  'Joan Baez'): ([Page('Caroline Kennedy'),\n",
       "   Page('Vietnam War'),\n",
       "   Page('Joan Baez')], 2),\n",
       " ('Written language',\n",
       "  'speech'): ([Page('Written language'), Page('Language'), Page('Speech')], 2),\n",
       " ('Waterboarding',\n",
       "  'Ecology'): ([Page('Waterboarding'),\n",
       "   Page('2003 invasion of Iraq'),\n",
       "   Page('Netherlands'),\n",
       "   Page('Ecology')],\n",
       "  9),\n",
       " ('Dance music',\n",
       "  'Pathology'): ([Page('Dance music'),\n",
       "   Page('Acid house'),\n",
       "   Page('Addiction'),\n",
       "   Page('Pathology')], 5),\n",
       " ('Computer science',\n",
       "  'Death of Adolf Hitler'): ([Page('Computer science'),\n",
       "   Page('World War II'),\n",
       "   Page('Death of Adolf Hitler')], 2),\n",
       " ('Bavaria',\n",
       "  'Canadians'): ([Page('Bavaria'),\n",
       "   Page('Adidas'),\n",
       "   Page('Greenpeace'),\n",
       "   Page('Canadians')], 6),\n",
       " ('Jellyfish',\n",
       "  'Bilirubin'): ([Page('Jellyfish'),\n",
       "   Page('Green fluorescent protein'),\n",
       "   Page('Bilirubin')], 2),\n",
       " ('War of 1812',\n",
       "  'Southern Europe'): ([Page('War of 1812'),\n",
       "   Page('Pacific Ocean'),\n",
       "   Page('Southern Europe')], 2),\n",
       " ('Al-Qaeda', 'Radio'): ([Page('Al-Qaeda'), Page('Japan'), Page('Radio')], 2),\n",
       " ('Cologne',\n",
       "  'Battleship'): ([Page('Cologne'),\n",
       "   Page('Aachen'),\n",
       "   Page('Artillery'),\n",
       "   Page('Battleship')], 19),\n",
       " ('Megalodon',\n",
       "  'Coaxial cable'): ([Page('Megalodon'),\n",
       "   Page('Angola'),\n",
       "   Page('Mass media'),\n",
       "   Page('Coaxial cable')], 75),\n",
       " ('Ralph Waldo Emerson',\n",
       "  'Marine biology'): ([Page('Ralph Waldo Emerson'),\n",
       "   Page('19th-century philosophy'),\n",
       "   Page('Outline of academic disciplines'),\n",
       "   Page('Marine biology')], 4),\n",
       " ('Documentary film',\n",
       "  'Bacteria'): ([Page('Documentary film'),\n",
       "   Page('Romania'),\n",
       "   Page('Bacteria')], 2),\n",
       " ('Auto racing',\n",
       "  'Ethernet'): ([Page('Auto racing'),\n",
       "   Page('2007 Indianapolis 500'),\n",
       "   Page('Television network'),\n",
       "   Page('Ethernet')], 22),\n",
       " ('Michelangelo',\n",
       "  'Horror Fiction'): ([Page('Michelangelo'),\n",
       "   Page('Italians'),\n",
       "   Page('Danube'),\n",
       "   Page('Algernon Blackwood'),\n",
       "   Page('Horror Fiction')], 328),\n",
       " ('Pony Express',\n",
       "  'Jacob'): ([Page('Pony Express'),\n",
       "   Page('Benjamin Franklin'),\n",
       "   Page('Augustine of Hippo'),\n",
       "   Page('Jacob')], 21),\n",
       " ('Prussia',\n",
       "  'nitrogen'): ([Page('Prussia'),\n",
       "   Page('Achievement (heraldry)'),\n",
       "   Page('Cattle'),\n",
       "   Page('Nitrogen')], 9),\n",
       " ('Americans',\n",
       "  'Rhodesia'): ([Page('Americans'), Page('Bermuda'), Page('Rhodesia')], 2),\n",
       " ('Nobel Prize in Physiology or Medicine',\n",
       "  'World Trade Organization'): ([Page('Nobel Prize in Physiology or Medicine'),\n",
       "   Page('Germany'),\n",
       "   Page('World Trade Organization')],\n",
       "  2),\n",
       " ('Engine',\n",
       "  'Multi-sport event'): ([Page('Engine'),\n",
       "   Page('Absorption refrigerator'),\n",
       "   Page('Stockholm'),\n",
       "   Page('Multi-sport event')], 3),\n",
       " ('Church of England',\n",
       "  'African-American music'): ([Page('Church of England'),\n",
       "   Page('Anglican Church of Chile'),\n",
       "   Page('United States'),\n",
       "   Page('African-American music')], 25),\n",
       " ('Sheep',\n",
       "  'James II of England'): ([Page('Sheep'),\n",
       "   Page('England'),\n",
       "   Page('James II of England')], 2),\n",
       " ('William Shakespeare',\n",
       "  'Nevada'): ([Page('William Shakespeare'),\n",
       "   Page(\"(Don't Fear) The Reaper\"),\n",
       "   Page('Richie Castellano'),\n",
       "   Page('Nevada')], 7),\n",
       " ('Ornithology',\n",
       "  'Google Chrome'): ([Page('Ornithology'),\n",
       "   Page('Birdwatching'),\n",
       "   Page('Internet'),\n",
       "   Page('Google Chrome')], 76),\n",
       " ('Radiohead',\n",
       "  'Armageddon'): ([Page('Radiohead'),\n",
       "   Page('A Moon Shaped Pool'),\n",
       "   Page('Climate change'),\n",
       "   Page('Armageddon')], 12),\n",
       " ('Ghetto',\n",
       "  'Dream'): ([Page('Ghetto'),\n",
       "   Page('Autonomy'),\n",
       "   Page('Aristotle'),\n",
       "   Page('Dream')], 13),\n",
       " ('Adolf Hitler',\n",
       "  'Vermont'): ([Page('Adolf Hitler'),\n",
       "   Page('Franklin D. Roosevelt'),\n",
       "   Page('Vermont')], 2),\n",
       " ('Parthenon',\n",
       "  'Mathematics'): ([Page('Parthenon'),\n",
       "   Page('Archimedes'),\n",
       "   Page('Mathematics')], 2),\n",
       " ('Potato',\n",
       "  \"Alzheimer's disease\"): ([Page('Potato'),\n",
       "   Page('Sugar'),\n",
       "   Page(\"Alzheimer's disease\")], 2),\n",
       " ('Comedian',\n",
       "  'Mark Wahlberg'): ([Page('Comedian'),\n",
       "   Page('Adam Sandler'),\n",
       "   Page('Mark Wahlberg')], 2),\n",
       " ('Bruce Lee',\n",
       "  'Jules Verne'): ([Page('Bruce Lee'),\n",
       "   Page('Actor'),\n",
       "   Page('Maurice Tourneur'),\n",
       "   Page('Jules Verne')], 5),\n",
       " ('Dictionary',\n",
       "  'Graphical User Interface'): ([Page('Dictionary'),\n",
       "   Page('Arabic'),\n",
       "   Page('Bulletin board system'),\n",
       "   Page('Graphical User Interface')], 29),\n",
       " ('Moors',\n",
       "  'Personal computer'): ([Page('Moors'),\n",
       "   Page('Arabic'),\n",
       "   Page('Personal computer')], 2),\n",
       " ('Humid subtropical climate',\n",
       "  'Mammal'): ([Page('Humid subtropical climate'),\n",
       "   Page('Bulgaria'),\n",
       "   Page('Mammal')], 2),\n",
       " ('Yellowstone National Park',\n",
       "  'Credit card'): ([Page('Yellowstone National Park'),\n",
       "   Page('American Civil War'),\n",
       "   Page('Banking in the United States'),\n",
       "   Page('Credit card')], 63),\n",
       " ('Jim Carrey',\n",
       "  'Latitude'): ([Page('Jim Carrey'),\n",
       "   Page('23 enigma'),\n",
       "   Page('Simon Newcomb'),\n",
       "   Page('Latitude')], 5),\n",
       " ('Natural Environment',\n",
       "  'Sociology'): ([Page('Natural Environment'),\n",
       "   Page('Natural environment'),\n",
       "   Page('Sociology')], 2),\n",
       " ('Profession',\n",
       "  'List of U.S. states and territories by area'): ([Page('Profession'),\n",
       "   Page('Accounting'),\n",
       "   Page('U.S. state'),\n",
       "   Page('List of U.S. states and territories by area')], 3),\n",
       " ('Nevada',\n",
       "  'Web search engine'): ([Page('Nevada'),\n",
       "   Page('United States'),\n",
       "   Page('Web search engine')], 2),\n",
       " ('World War II',\n",
       "  'Mathematics'): ([Page('World War II'),\n",
       "   Page('Asia'),\n",
       "   Page('Mathematics')], 2),\n",
       " ('Brain tumor',\n",
       "  'Pistol'): ([Page('Brain tumor'),\n",
       "   Page('CT scan'),\n",
       "   Page('Airport security'),\n",
       "   Page('Pistol')], 38),\n",
       " ('The Cosby Show',\n",
       "  'Eurozone'): ([Page('The Cosby Show'),\n",
       "   Page('2008–09 United States network television schedule'),\n",
       "   Page(\"Don't Forget the Lyrics!\"),\n",
       "   Page('Eurozone')], 63),\n",
       " ('Lead',\n",
       "  'Typhoid fever'): ([Page('Lead'),\n",
       "   Page('Centers for Disease Control and Prevention'),\n",
       "   Page('Typhoid fever')], 2),\n",
       " ('Fashion',\n",
       "  'Bette Midler'): ([Page('Fashion'),\n",
       "   Page('1930–1945 in Western fashion'),\n",
       "   Page('Fred Astaire'),\n",
       "   Page('Bette Midler')], 29),\n",
       " ('Death',\n",
       "  'Apple Lisa'): ([Page('Death'),\n",
       "   Page('Biodiversity'),\n",
       "   Page('Acronym'),\n",
       "   Page('Apple Lisa')], 58),\n",
       " ('Electron',\n",
       "  'Bosnia and Herzegovina'): ([Page('Electron'),\n",
       "   Page('1'),\n",
       "   Page('122 (number)'),\n",
       "   Page('Bosnia and Herzegovina')], 11),\n",
       " ('String theory',\n",
       "  'Gastroesophageal reflux disease'): ([Page('String theory'),\n",
       "   Page('Albert Einstein'),\n",
       "   Page('Rudolph Nissen'),\n",
       "   Page('Gastroesophageal reflux disease')], 15),\n",
       " ('Nuclear Power',\n",
       "  'Breakfast'): ([Page('Nuclear Power'),\n",
       "   Page('Nuclear power'),\n",
       "   Page('Food'),\n",
       "   Page('Breakfast')], 3),\n",
       " ('Aryan',\n",
       "  'Magnetic resonance imaging'): ([Page('Aryan'),\n",
       "   Page('Adolf Hitler'),\n",
       "   Page('Amphetamine'),\n",
       "   Page('Magnetic resonance imaging')], 14),\n",
       " ('Persecution of Christians',\n",
       "  'Wall Street'): ([Page('Persecution of Christians'),\n",
       "   Page('American Civil War'),\n",
       "   Page('Wall Street')], 2),\n",
       " ('Tomato',\n",
       "  'Stock market'): ([Page('Tomato'),\n",
       "   Page('Iceland'),\n",
       "   Page('Stock market')], 2),\n",
       " ('Nuclear warfare',\n",
       "  'DNA replication'): ([Page('Nuclear warfare'),\n",
       "   Page('1,000,000,000'),\n",
       "   Page('Eukaryote'),\n",
       "   Page('DNA replication')], 8),\n",
       " ('Dimension',\n",
       "  'Memory'): ([Page('Dimension'),\n",
       "   Page('Experimental psychology'),\n",
       "   Page('Memory')], 2),\n",
       " ('Periodic table',\n",
       "  'Gastroesophageal reflux disease'): ([Page('Periodic table'),\n",
       "   Page('Aluminium'),\n",
       "   Page('Antacid'),\n",
       "   Page('Gastroesophageal reflux disease')], 18),\n",
       " ('Southern California',\n",
       "  'Diazepam'): ([Page('Southern California'),\n",
       "   Page(\"America's Cup\"),\n",
       "   Page('Switzerland'),\n",
       "   Page('Diazepam')], 15),\n",
       " ('Charles Bronson',\n",
       "  'Architecture'): ([Page('Charles Bronson'),\n",
       "   Page('Architect'),\n",
       "   Page('Architecture')], 2),\n",
       " ('Romanticism',\n",
       "  'Sigmund Freud'): ([Page('Romanticism'),\n",
       "   Page('Arthur Schopenhauer'),\n",
       "   Page('Sigmund Freud')], 2),\n",
       " ('Internal combustion engine',\n",
       "  'Ballet'): ([Page('Internal combustion engine'),\n",
       "   Page('Aircraft'),\n",
       "   Page('Kite'),\n",
       "   Page('Ballet')], 19),\n",
       " ('J. R. R. Tolkien',\n",
       "  'Luciano Pavarotti'): ([Page('J. R. R. Tolkien'),\n",
       "   Page('100 Greatest Britons'),\n",
       "   Page('Bono'),\n",
       "   Page('Luciano Pavarotti')], 7),\n",
       " ('Ecosystem',\n",
       "  'Four Tops'): ([Page('Ecosystem'),\n",
       "   Page('Africa'),\n",
       "   Page('Midwestern United States'),\n",
       "   Page('Four Tops')], 11),\n",
       " ('Frank Gehry',\n",
       "  'Will Smith'): ([Page('Frank Gehry'),\n",
       "   Page('Robert Redford'),\n",
       "   Page('Will Smith')], 2),\n",
       " ('Feces',\n",
       "  'Entertainment'): ([Page('Feces'),\n",
       "   Page('Science'),\n",
       "   Page('Entertainment')], 2),\n",
       " ('Louis Armstrong',\n",
       "  'Airline'): ([Page('Louis Armstrong'),\n",
       "   Page('Andy Razaf'),\n",
       "   Page('Greyhound Lines'),\n",
       "   Page('Airline')], 27),\n",
       " ('Constantinople',\n",
       "  'Montreal'): ([Page('Constantinople'), Page('Athens'), Page('Montreal')], 2),\n",
       " ('Pulmonary embolism',\n",
       "  'Periodic table'): ([Page('Pulmonary embolism'),\n",
       "   Page('Technetium'),\n",
       "   Page('Periodic table')],\n",
       "  2),\n",
       " ('Onomatopoeia',\n",
       "  'Apple Lisa'): ([Page('Onomatopoeia'),\n",
       "   Page('Advertising'),\n",
       "   Page('Apple Inc.'),\n",
       "   Page('Apple Lisa')], 4),\n",
       " ('Birdman (rapper)',\n",
       "  'Taxonomy (biology)'): ([Page('Birdman (rapper)'),\n",
       "   Page('Drug possession'),\n",
       "   Page('Amanita muscaria'),\n",
       "   Page('Taxonomy (biology)')], 36),\n",
       " ('Lacrosse',\n",
       "  'Satire'): ([Page('Lacrosse'),\n",
       "   Page('2000 Summer Olympics'),\n",
       "   Page('MetroTV'),\n",
       "   Page('Satire')], 7),\n",
       " ('Chemical reaction',\n",
       "  'Matter'): ([Page('Chemical reaction'), Page('Alchemy'), Page('Matter')], 2),\n",
       " ('Continental Army',\n",
       "  'Organization'): ([Page('Continental Army'),\n",
       "   Page('Aide-de-camp'),\n",
       "   Page('Secretary'),\n",
       "   Page('Organization')],\n",
       "  27),\n",
       " ('Americans',\n",
       "  'West Indies'): ([Page('Americans'), Page('Asia'), Page('West Indies')], 2),\n",
       " ('Carrie Fisher',\n",
       "  'Ant'): ([Page('Carrie Fisher'), Page('Harrison Ford'), Page('Ant')], 2),\n",
       " ('Climate',\n",
       "  'Atmosphere of Earth'): ([Page('Climate'), Page('Atmosphere of Earth')], 1),\n",
       " ('Train',\n",
       "  'Envy'): ([Page('Train'),\n",
       "   Page('Bicycle'),\n",
       "   Page('Conspicuous consumption'),\n",
       "   Page('Envy')],\n",
       "  23),\n",
       " ('Early Middle Ages',\n",
       "  'Ku Klux Klan'): ([Page('Early Middle Ages'),\n",
       "   Page('Khazars'),\n",
       "   Page('Ku Klux Klan')], 2),\n",
       " ('Augustus',\n",
       "  'Magnetic field'): ([Page('Augustus'),\n",
       "   Page('Adriatic Sea'),\n",
       "   Page('Moon'),\n",
       "   Page('Magnetic field')], 13),\n",
       " ('Parthenon',\n",
       "  'United Nations Charter'): ([Page('Parthenon'),\n",
       "   Page('Achaemenid Empire'),\n",
       "   Page('Economic Cooperation Organization'),\n",
       "   Page('United Nations Charter')], 9),\n",
       " ('Metaphysics',\n",
       "  'Technology'): ([Page('Metaphysics'),\n",
       "   Page('Anarchism'),\n",
       "   Page('Technology')], 2),\n",
       " ('Polynesia',\n",
       "  'Queens of the Stone Age'): ([Page('Polynesia'),\n",
       "   Page('Baltic states'),\n",
       "   Page('Elton John'),\n",
       "   Page('Queens of the Stone Age')], 136),\n",
       " ('Computer Multitasking', 'Broadway theatre'): (False, 2),\n",
       " ('Celsius',\n",
       "  'Wiki'): ([Page('Celsius'),\n",
       "   Page('Encyclopædia Britannica'),\n",
       "   Page('Wiki')], 2),\n",
       " ('Mick Jagger',\n",
       "  'Personal digital assistant'): ([Page('Mick Jagger'),\n",
       "   Page('MSN'),\n",
       "   Page('Personal digital assistant')], 2),\n",
       " ('Ashley Massaro',\n",
       "  'Embedded system'): ([Page('Ashley Massaro'),\n",
       "   Page('Adam Klein (Survivor contestant)'),\n",
       "   Page('Stanford University'),\n",
       "   Page('Embedded system')], 3)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-92903e21deee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mthing\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthing\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mlens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthing\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "lens = []\n",
    "for thing in output.keys():\n",
    "    path = output[thing][0]\n",
    "    if path != False:\n",
    "        lens.append(len(output[thing][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_lens=list(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_lens.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sorted_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5816326530612246"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "351/98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

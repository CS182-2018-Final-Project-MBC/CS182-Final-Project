{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywikibot\n",
    "import queue\n",
    "import gensim\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppresses gensim errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things I've installed:\n",
    "1. wikipedia (query wikipedia) - not used\n",
    "2. pywikibot (more advanced queries)\n",
    "3. wikiutils (read sql.gz files) - not yet used. possibly in the future\n",
    "4. gensim (for NLP and specifically using Google's word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obviously override this to your local location\n",
    "model_addr = '/Users/benjaminrafetto/Code/cs182/project/data/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(model_addr, binary=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crude definition of distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently uses average word distances from word2vec embeddings\n",
    "def get_distance(topic, model, goal):\n",
    "    if topic in model:\n",
    "        return model.distance(goal, topic)\n",
    "    else:\n",
    "        distances = [model.distance(goal, w) for w in topic.split(' ') if w in model]\n",
    "        return np.average(distances) if distances else np.Infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = pywikibot.Site(\"en\", \"wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_word2vec_path(start, goal, maxIters=30, verbose=False):\n",
    "    assert start in model and goal in model, f\"Start and end nodes {start} and {goal} must be in word2vec vocabulary.\"\n",
    "    start_page = pywikibot.Page(site, start)\n",
    "    path = []\n",
    "    visited = []\n",
    "    fringe = queue.PriorityQueue()\n",
    "    fringe.put((np.Inf, start_page))\n",
    "    \n",
    "    i = 0\n",
    "    while i < maxIters and not fringe.empty():\n",
    "        i += 1\n",
    "        priority, page = fringe.get()\n",
    "        path.append(page.title())\n",
    "        if verbose:\n",
    "            print(\"Exploring node {} with distance {}\".format(page.title(), priority))\n",
    "        if goal.lower() == page.title().lower():\n",
    "            return path\n",
    "\n",
    "        for p in page.linkedPages():\n",
    "            if p.title() not in visited:\n",
    "                visited.append(p.title())\n",
    "                distance = get_distance(p.title(), model, goal)\n",
    "                fringe.put((distance, p))\n",
    "\n",
    "    raise Exception(\"Unable to find goal node.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some example paths. Currently only supports start and goal nodes that are specifically in word2vec.\n",
    "i.e. Sentences don't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [(\"speech\", \"lacrosse\"),\n",
    "            (\"mantra\", \"dna\"),\n",
    "            (\"Parthenon\", \"Environment\"),  #\"Natural Environment\"\n",
    "            (\"Feces\", \"Poet\")\n",
    "#             (\"penguin\", \"sans-serif\"),\n",
    "#             (\"angelina jolie\", \"nitrogen\"),\n",
    "#             (\"Carrie Fisher\", \"Death of Adolf Hitler\"),\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for shortest path from mantra to dna\n"
     ]
    }
   ],
   "source": [
    "start, goal = examples[np.random.choice(len(examples))]\n",
    "print(f\"Searching for shortest path from {start} to {goal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mantra',\n",
       " 'Rigveda',\n",
       " 'Brahmanda Purana',\n",
       " 'Brihaddharma Purana',\n",
       " 'Devi-Bhagavata Purana',\n",
       " 'Brahmavaivarta Purana',\n",
       " 'Mudgala Purana',\n",
       " 'Naradiya Purana',\n",
       " 'Purana',\n",
       " 'Category:Redirects to plurals',\n",
       " 'Shivarahasya Purana',\n",
       " 'Vishnudharmottara Purana',\n",
       " 'PubMed Identifier',\n",
       " 'PubMed',\n",
       " 'Entrez',\n",
       " 'PubChem',\n",
       " 'GenBank',\n",
       " 'RefSeq',\n",
       " 'Ensembl',\n",
       " 'Geneious',\n",
       " 'Sequence database',\n",
       " 'Biological database',\n",
       " 'Biobank',\n",
       " 'Caenorhabditis briggsae',\n",
       " 'Caenorhabditis',\n",
       " 'Caenorhabditis afra',\n",
       " 'Caenorhabditis angaria',\n",
       " 'Caenorhabditis brenneri',\n",
       " 'Caenorhabditis castelli',\n",
       " 'Caenorhabditis doughertyi',\n",
       " 'Caenorhabditis drosophilae',\n",
       " 'Caenorhabditis guadeloupensis',\n",
       " 'Caenorhabditis imperialis',\n",
       " 'Caenorhabditis inopinata',\n",
       " 'Caenorhabditis latens',\n",
       " 'Caenorhabditis macrosperma',\n",
       " 'Caenorhabditis monodelphis',\n",
       " 'Caenorhabditis nigoni',\n",
       " 'Caenorhabditis nouraguensis',\n",
       " 'Caenorhabditis plicata',\n",
       " 'Caenorhabditis portoensis',\n",
       " 'Caenorhabditis remanei',\n",
       " 'Caenorhabditis sinica',\n",
       " 'Caenorhabditis sp. 35',\n",
       " 'Caenorhabditis virilis',\n",
       " 'Caenorhabditis wallacei',\n",
       " 'Caenorhabditis yunquensis',\n",
       " 'Metabolomics',\n",
       " 'Metagenomics',\n",
       " 'DNA']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_word2vec_path(start, goal, maxIters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
